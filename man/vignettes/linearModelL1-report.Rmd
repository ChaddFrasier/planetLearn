---
title: "L1 Regularized Linear Model"
author: "Chadd Frasier"
output: html_document
---

```{r setup}
library(knitr)
library(planetLearn)
```
## Introduction
Machine Learning is the fastest growing field of computer science and its applications can be observed in every science from Marine Biology, where they predict locations of whale gams based on ocean ambient temperatures, to Astrophysics, where we can predict locations of black holes based on tiny variations in image data. Linear models have been used for all kinds of classification and regression problems and the methods are only getting better. First we need to isolate the data rows that have incidence angles of 70$^\circ$ or less. This is because an incidence angles of 90$^\circ$ tells us that the sun is below the horizon and therefore should not be used in any image. We then need to apply the cosine to the Emission, Incidence, Local Emission, and Local Incidence angles of each observation ( row ) in the data. This is done to comply with the driving theory behind these predictions, the Minnaert equation for photometric surface scattering. Minnaert's theory states that the scattering value of the planetary surface is based on the angles that the light particles hit the camera's detectors. This theory is what allows us to convert raw angles values picked up by the camera to a pixel values in a complete image. Dr. Laszlo Kestay predicts that we can generate linear models of the Minnaert equation for the purpose of predicting surface scattering of lunar data set. We need a mission with millions of observations and LROC is a perfect canidate. We use this data set to train differnet linear models on 80% of the observations and testing using the rest of the observations. We perform Cross-Validation to select the most ideal training set for the set and then return the best model. Since Lasso regression uses a lambda and an alpha perameter we will need to perform the CV for each train/test split twince, once for the alpha and another time for the lambda. Then we display the best prediction results. 

## Read the Data in R
```{r, Data Init}
# set column names for the data features and label column ( DN )
col_names <- c("DN", "Phase", "Emission", "Incidence", "LEmission", "LIncidence", "Lat", "Long", "SunAz", "CraftAz")
# Read Data in from text file and set column names
data <- read.table( "../../inst/extdata/band1unit7.dat", stringsAsFactors=FALSE, 
                   header=FALSE, strip.white=TRUE, sep="", col.names=col_names)
# convert to a matrix
data <- as.data.frame(data)
```

## Isolate Labels and Features
```{r, Preping & Scaling }
# isolate the labels
y.vec <- data[,1]
# isolate the features
X.mat <- data[, -1]
# show
str(y.vec)
str(X.mat)
```

## Prepair Remaining Variables
```{r, Prep }
set.seed(030796)
# create fold number and auto generate the vector
n.folds <- 7
fold.vec <- sample(rep(1:n.folds, l=nrow(X.mat)))

# create the penalty vector
penalty.vec <- 10^seq(0,-2, by = -.025)
```

## Call the CV function
```{r, CV, echo=TRUE}
result.list <- planetLearn::LinearModelL1CV( X.train, y.train, fold.vec, n.folds, penalty.vec, step.size)

result.list
```
